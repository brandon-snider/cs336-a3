{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d: 96, L: 2, h: 2, n_realized: 6,365,184, n_realized_non_embed: 221,184, err: 3,478,433 err_pct: 120.50%\n",
      "Time taken: 0.0014 seconds\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 32000\n",
    "\n",
    "\n",
    "def non_embed_params(d_model: int, num_layers: int) -> int:\n",
    "    return 12 * num_layers * d_model**2\n",
    "\n",
    "\n",
    "def embed_params(d_model: int) -> int:\n",
    "    return 2 * VOCAB_SIZE * d_model\n",
    "\n",
    "\n",
    "def total_params(d_model: int, num_layers: int) -> int:\n",
    "    return non_embed_params(d_model, num_layers) + embed_params(d_model)\n",
    "\n",
    "\n",
    "def chinchilla_n_for_c(c: int, tokens_per_param: float = 20) -> int:\n",
    "    return int(np.sqrt(c / (6 * tokens_per_param)))\n",
    "\n",
    "\n",
    "def get_shape_for_n(\n",
    "    n_target: int, n_is_total: bool = False\n",
    ") -> tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Find and return a transformer shape (d, L, h) that gets as close as possible to n_target.\n",
    "\n",
    "    If `n_is_total` is True, `n_target` should represent the *total* number of parameters.\n",
    "    Otherwise, `n_target` should represent the number of *non-embedding* parameters.\n",
    "\n",
    "    If `n_is_total` is True:\n",
    "        Solve 12Ld^2 + 2Vd = n, keeping L in [2, 24], d in [64, 1024], h in [2, 16]\n",
    "    Otherwise:\n",
    "        Solve 12Ld^2 = n, keeping L in [2, 24], d in [64, 1024], h in [2, 16]\n",
    "    \"\"\"\n",
    "    closest = None, None, None, None  # d, l, h, n_star\n",
    "\n",
    "    for d, L, h in itertools.product(range(64, 1025, 32), range(2, 25), range(2, 17)):\n",
    "        aspect_ratio = d / L\n",
    "        min_aspect_ratio = 48 if n_target < 1e8 else 64\n",
    "\n",
    "        if aspect_ratio < min_aspect_ratio or aspect_ratio > 256:\n",
    "            continue\n",
    "\n",
    "        head_dim = d / h\n",
    "\n",
    "        head_dim_ratio = 16 if n_target < 1e8 else 64\n",
    "\n",
    "        if head_dim < 16 or head_dim > 128 or head_dim % head_dim_ratio != 0:\n",
    "            continue\n",
    "\n",
    "        if n_is_total:\n",
    "            n_star = 12 * L * d**2 + 2 * VOCAB_SIZE * d\n",
    "        else:\n",
    "            n_star = 12 * L * d**2\n",
    "\n",
    "        closest_n_star = closest[3]\n",
    "        if not closest_n_star or abs(n_star - n_target) < abs(\n",
    "            closest_n_star - n_target\n",
    "        ):\n",
    "            closest = d, L, h, n_star\n",
    "\n",
    "    d, L, h, n_star = closest\n",
    "    err = abs(n_star - n_target)\n",
    "    err_pct = err * 100 / n_target\n",
    "\n",
    "    return d, L, h, n_star, err, err_pct\n",
    "\n",
    "\n",
    "c = 1e15\n",
    "\n",
    "n_guess = chinchilla_n_for_c(\n",
    "    c, tokens_per_param=20\n",
    ")  # total params to hit 20 tokens per param\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "d, L, h, n_realized, err, err_pct = get_shape_for_n(n_guess, n_is_total=True)\n",
    "n_realized_non_embed = 12 * L * d**2\n",
    "print(\n",
    "    f\"d: {d}, L: {L}, h: {h}, n_realized: {n_realized:,}, n_realized_non_embed: {n_realized_non_embed:,}, err: {err:,} err_pct: {err_pct:.2f}%\"\n",
    ")\n",
    "\n",
    "print(f\"Time taken: {time.perf_counter() - t0:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
